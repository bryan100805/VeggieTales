{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Tan Wen Tao Bryan <br>\n",
    "Admin No: P2214449 <br>\n",
    "Class: DAAA/FT/2B/01<br>\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create docker container by pulling image for Docker Hub<br>\n",
    "`docker pull python:3.8`<br>\n",
    "\n",
    "- Run a Docker container with the name DLMODEL_Server_CA2 using the downloaded image for Python 3.8 <br>\n",
    "`docker run -tid -v /var/run/docker.sock:/var/run/docker.sock --name DLMODEL_Server_CA2 python:3.8`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 23:22:32.031150: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-12 23:22:32.069475: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-12 23:22:32.394356: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-12 23:22:32.395671: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-12 23:22:33.597353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import save_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./img_classifier/veggie_cnn_31x31/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./img_classifier/veggie_cnn_31x31/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./img_classifier/veggie_cnn_128x128/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./img_classifier/veggie_cnn_128x128/assets\n"
     ]
    }
   ],
   "source": [
    "# Load the models weights\n",
    "veggie_cnn_31x31 = load_model('./DL_models/Final_31x31_Model.h5')\n",
    "veggie_cnn_128x128 = load_model('./DL_models/Final_128x128_Model.h5')\n",
    "\n",
    "# Save the models into img_classifier folder\n",
    "save_model(veggie_cnn_31x31, \"./img_classifier/veggie_cnn_31x31\", save_format=\"tf\")\n",
    "save_model(veggie_cnn_128x128, \"./img_classifier/veggie_cnn_128x128\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying both models locally\n",
    "\n",
    "- Serve the 2 models on tensorflow-serving and deploy it locally<br>\n",
    "`docker run --name vegetable_cnn -p 8501:8501 -v \"D:/ca2-daaa2b01-2214449-tanwentaobryan-img_classifier/img_classifier:/models/img_classifier\" -t tensorflow/serving --model_config_file=/models/img_classifier/conf/models.config &`<br>\n",
    "\n",
    "<b>models.config</b> <br>\n",
    "```\n",
    "model_config_list: {\n",
    "  config: {\n",
    "    name:  \"veggie_cnn_31x31\",\n",
    "    base_path:  \"/img_classifier/veggie_cnn_31x31\",\n",
    "    model_platform: \"tensorflow\",\n",
    "    model_version_policy: {\n",
    "        all: {}\n",
    "    }\n",
    "  },\n",
    "  config: {\n",
    "    name:  \"veggie_cnn_128x128\",\n",
    "    base_path:  \"/img_classifier/veggie_cnn_128x128\",\n",
    "    model_platform: \"tensorflow\",\n",
    "    model_version_policy: {\n",
    "        all: {}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Output: http://localhost:8501/v1/models/veggie_cnn_31x31<br>\n",
    "```\n",
    "{\n",
    "    \"model_version_status\": [\n",
    "        {\n",
    "            \"version\": \"2024011301\",\n",
    "            \"state\": \"AVAILABLE\",\n",
    "            \"status\": {\n",
    "                \"error_code\": \"OK\",\n",
    "                \"error_message\": \"\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Output: http://localhost:8501/v1/models/veggie_cnn_128x128<br>\n",
    "```\n",
    "{\n",
    "    \"model_version_status\": [\n",
    "        {\n",
    "            \"version\": \"2024011302\",\n",
    "            \"state\": \"AVAILABLE\",\n",
    "            \"status\": {\n",
    "                \"error_code\": \"OK\",\n",
    "                \"error_message\": \"\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect both development container and vegetable_cnn to the same network\n",
    "\n",
    "- Create a network<br>\n",
    "`docker network create veggie_ml_network`<br>\n",
    "\n",
    "- Connect vegetable_cnn to veggie_ml_network<br>\n",
    "`docker network connect veggie_ml_network vegetable_cnn`<br>\n",
    "\n",
    "- Connect DLMODEL_Server_CA2 to veggie_ml_network<br>\n",
    "`docker network connect veggie_ml_network DLMODEL_Server_CA2`<br>\n",
    "\n",
    "- Install ping program via bash<br>\n",
    "`apt-get update`<br>\n",
    "`apt-get install iputils-ping`<br>\n",
    "\n",
    "- Check to see if the DLMODEL_Server_CA2 container is running and check the connection to vegetable_cnn <br>\n",
    "`ping vegetable_cnn`\n",
    "\n",
    "\n",
    "**Output:** <br>\n",
    "`64 bytes from vegetable_cnn.veggie_ml_network (172.19.0.2): icmp_seq=21 ttl=64 time=0.042 ms`<br>\n",
    "`64 bytes from vegetable_cnn.veggie_ml_network (172.19.0.2): icmp_seq=22 ttl=64 time=0.069 ms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_docker_local.py \n",
    "- Testing was done to ensure that the 2 models are able to make predictions\n",
    "- Checks if the local deployement of models work successfully\n",
    "```\n",
    "import pytest\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Server URLs (test local deployment)\n",
    "url_31x31 = \"http://vegetable_cnn:8501/v1/models/veggie_cnn_31x31:predict\"\n",
    "url_128x128 = \"http://vegetable_cnn:8501/v1/models/veggie_cnn_128x128:predict\"\n",
    "\n",
    "# Load test images from images folder\n",
    "def load_image(img_size):\n",
    "    local_path = os.path.join(os.getcwd(), 'tests/images')\n",
    "    images_list = []\n",
    "    for label in os.listdir(local_path):\n",
    "        for filename in os.listdir(os.path.join(local_path,label)):\n",
    "            # Load image of specified size and feature scale\n",
    "            img = image.load_img(os.path.join(local_path,label, filename), color_mode='grayscale', target_size=(img_size, img_size))\n",
    "            img = image.img_to_array(img)/255.0\n",
    "            # Reshape image to (1, img_size, img_size, 1)\n",
    "            img = img.reshape(1, img_size, img_size, 1)\n",
    "            images_list.append(img)\n",
    "    return images_list\n",
    "\n",
    "# Predict using test images\n",
    "def make_prediction(instances, url):\n",
    "    # Send POST API request to server\n",
    "    data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": instances.tolist()})\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "    json_response = requests.post(url, data=data, headers=headers)\n",
    "    # Parse response\n",
    "    predictions = json.loads(json_response.text)['predictions']\n",
    "    return predictions\n",
    "\n",
    "# Test prediction for 31x31 model\n",
    "def test_prediction_31():\n",
    "    data = load_image(31)\n",
    "    for img in data:\n",
    "        predictions = make_prediction(img, url_31x31)\n",
    "        # Check if prediction is a list\n",
    "        assert isinstance(predictions, list)\n",
    "        # Check if prediction is a list of length 1\n",
    "        assert len(predictions) == 1\n",
    "        # Check if each prediction is a float\n",
    "        assert isinstance(predictions[0][0], float)\n",
    "\n",
    "# Test prediction for 128x128 model\n",
    "def test_prediction_128():\n",
    "    data = load_image(128)\n",
    "    for img in data:\n",
    "        predictions = make_prediction(img, url_128x128)\n",
    "        # Check if prediction is a list\n",
    "        assert isinstance(predictions, list)\n",
    "        # Check if prediction is a list of length 1\n",
    "        assert len(predictions) == 1\n",
    "        # Check if prediction is a float\n",
    "        assert isinstance(predictions[0][0], float)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying both models remotely\n",
    "<b>Dockerfile</b> <br>\n",
    "```\n",
    "FROM tensorflow/serving\n",
    "COPY / /\n",
    "ENV MODEL_CONF=/img_classifier/models.config MODEL_BASE_PATH=/\n",
    "EXPOSE 8500\n",
    "EXPOSE 8501\n",
    "RUN echo '#!/bin/bash \\n\\n\\\n",
    "tensorflow_model_server \\\n",
    "--rest_api_port=$PORT \\\n",
    "--model_config_file=${MODEL_CONF} \\\n",
    "\"$@\"' > /usr/bin/tf_serving_entrypoint.sh \\\n",
    "&& chmod +x /usr/bin/tf_serving_entrypoint.sh\n",
    "```\n",
    "Code Meaning:\n",
    "- `FROM tensorflow/serving` - Initializes a new build stage and sets the Base Image (tensorflow/serving) for subsequent instructions.\n",
    "- `COPY / /` - Copies new files or directories from source `root` and adds them to the file system of the container at the path `root`.\n",
    "- `ENV MODEL_CONF=/img_classifier/models.config` - Sets environment variable to the specified config file\n",
    "- `EXPOSE 8500 EXPOSE 8501` - Exposes specified ports to inform Docker that the container listens on the specified network ports at runtime\n",
    "- `RUN echo '#!/bin/bash \\n\\n\n",
    "tensorflow_model_server \n",
    "--rest_api_port=$PORT \n",
    "--model_config_file=${MODEL_CONF} \n",
    "\"$@\"' > /usr/bin/tf_serving_entrypoint.sh \n",
    "&& chmod +x /usr/bin/tf_serving_entrypoint.sh` - Executes any commands in a new layer on top of the current image and commit the results\n",
    "\n",
    "- Lastly, the models are deployed on render as a web service via Docker<br>\n",
    "\n",
    "Output: https://veggietales-cnn.onrender.com/v1/models/veggie_cnn_31x31<br>\n",
    "```\n",
    "{\n",
    " \"model_version_status\": [\n",
    "  {\n",
    "   \"version\": \"202401\",\n",
    "   \"state\": \"AVAILABLE\",\n",
    "   \"status\": {\n",
    "    \"error_code\": \"OK\",\n",
    "    \"error_message\": \"\"\n",
    "   }\n",
    "  }\n",
    " ]\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "Output: https://veggietales-cnn.onrender.com/v1/models/veggie_cnn_128x128<br>\n",
    "```\n",
    "{\n",
    " \"model_version_status\": [\n",
    "  {\n",
    "   \"version\": \"202402\",\n",
    "   \"state\": \"AVAILABLE\",\n",
    "   \"status\": {\n",
    "    \"error_code\": \"OK\",\n",
    "    \"error_message\": \"\"\n",
    "   }\n",
    "  }\n",
    " ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_docker_global.py \n",
    "- Testing was done to ensure that the 2 models are able to make predictions\n",
    "- Checks if the remote deployement of models on render work successfully\n",
    "```\n",
    "import pytest\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Server URLs (test rempte deployment)\n",
    "url_31x31 = \"https://veggietales-cnn.onrender.com/v1/models/veggie_cnn_31x31:predict\"\n",
    "url_128x128 = \"https://veggietales-cnn.onrender.com/v1/models/veggie_cnn_128x128:predict\"\n",
    "\n",
    "# Load test images from images folder\n",
    "def load_image(img_size):\n",
    "    local_path = os.path.join(os.getcwd(), 'tests/images')\n",
    "    images_list = []\n",
    "    for label in os.listdir(local_path):\n",
    "        for filename in os.listdir(os.path.join(local_path,label)):\n",
    "            # Load image of specified size and feature scale\n",
    "            img = image.load_img(os.path.join(local_path,label, filename), color_mode='grayscale', target_size=(img_size, img_size))\n",
    "            img = image.img_to_array(img)/255.0\n",
    "            # Reshape image to (1, img_size, img_size, 1)\n",
    "            img = img.reshape(1, img_size, img_size, 1)\n",
    "            images_list.append(img)\n",
    "    return images_list\n",
    "\n",
    "# Predict using test images\n",
    "def make_prediction(instances, url):\n",
    "    # Send POST API request to server\n",
    "    data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": instances.tolist()})\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "    json_response = requests.post(url, data=data, headers=headers)\n",
    "    # Parse response\n",
    "    predictions = json.loads(json_response.text)['predictions']\n",
    "    return predictions\n",
    "\n",
    "# Test prediction for 31x31 model\n",
    "def test_prediction_31():\n",
    "    data = load_image(31)\n",
    "    for img in data:\n",
    "        predictions = make_prediction(img, url_31x31)\n",
    "        # Check if prediction is a list\n",
    "        assert isinstance(predictions, list)\n",
    "        # Check if prediction is a list of length 1\n",
    "        assert len(predictions) == 1\n",
    "        # Check if each prediction is a float\n",
    "        assert isinstance(predictions[0][0], float)\n",
    "\n",
    "# Test prediction for 128x128 model\n",
    "def test_prediction_128():\n",
    "    data = load_image(128)\n",
    "    for img in data:\n",
    "        predictions = make_prediction(img, url_128x128)\n",
    "        # Check if prediction is a list\n",
    "        assert isinstance(predictions, list)\n",
    "        # Check if prediction is a list of length 1\n",
    "        assert len(predictions) == 1\n",
    "        # Check if prediction is a float\n",
    "        assert isinstance(predictions[0][0], float)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of both tests - both tests pass\n",
    "```\n",
    "tests/test_docker_global.py ..                                                                                                                                                 [ 50%]\n",
    "tests/test_docker_local.py ..                                                                                                                                                  [100%]\n",
    "\n",
    "====================================================================== 4 passed in 4.10s ====================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CI/CD - Model Testing & Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "stages:\n",
    "  - test\n",
    "  - deploy\n",
    "  - notification\n",
    "\n",
    "pytest:\n",
    "  stage: test\n",
    "  before_script:\n",
    "    - pwd\n",
    "  image: python:3.8\n",
    "  script:\n",
    "    - pip install -r requirements.txt\n",
    "    # Skip local deployment test because docker does not store the local files used to run the test in the container environment\n",
    "    - python -m pytest -k \"not tests/test_docker_local.py\" --junitxml=junit.xml\n",
    "  artifacts:\n",
    "    reports:\n",
    "      junit: junit.xml\n",
    "\n",
    "deployment:\n",
    "  stage: deploy\n",
    "  script:\n",
    "    - curl https://veggietales-cnn.onrender.com/v1/models/veggie_cnn_31x31\n",
    "    - curl https://veggietales-cnn.onrender.com/v1/models/veggie_cnn_128x128\n",
    "  only:\n",
    "    - main\n",
    "\n",
    "notification:\n",
    "  stage: notification\n",
    "  script:\n",
    "    # Notifies team channel if pipeline succeed or failed on discord channel through discord webhooks\n",
    "    - 'if [ \"$CI_PIPELINE_STATUS\" == \"success\" ]; then curl -X POST -H \"Content-type: application/json\" --data \"{\\\"content\\\":\\\"Pipeline Succeeded: $CI_COMMIT_REF_NAME - $CI_COMMIT_TITLE\\\"}\" https://discord.com/api/webhooks/1200457121326710914/8NBM-ImDrvrtSmNB-Ynay07tBz9H5NvLC64gJSF9W1Vu5DluE-UrulhCuCu28gYy08Hy; fi'\n",
    "    - 'if [ \"$CI_PIPELINE_STATUS\" == \"failed\" ]; then curl -X POST -H \"Content-type: application/json\" --data \"{\\\"content\\\":\\\"Pipeline Failed: $CI_COMMIT_REF_NAME - $CI_COMMIT_TITLE\\\"}\" https://discord.com/api/webhooks/1200457121326710914/8NBM-ImDrvrtSmNB-Ynay07tBz9H5NvLC64gJSF9W1Vu5DluE-UrulhCuCu28gYy08Hy; fi'\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
